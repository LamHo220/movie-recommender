{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVDModel import SVDModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(3362)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': {'ml': './data/MovieLens25M/', 'netflix': './data/NetflixPrize/'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "PARAM = dict()\n",
    "PARAM['path'] = {\n",
    "  'ml':'./data/MovieLens25M/',\n",
    "  'netflix':'./data/NetflixPrize/'\n",
    "}\n",
    "\n",
    "PARAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['userId','rating','timestamp','movieId']\n",
    "df_netflix = pd.read_csv(PARAM['path']['netflix']+'data_1.txt', names=names, low_memory=False)\n",
    "df_netflix_2 = pd.read_csv(PARAM['path']['netflix']+'data_2.txt', names=names, low_memory=False)\n",
    "df_netflix_3 = pd.read_csv(PARAM['path']['netflix']+'data_3.txt', names=names, low_memory=False)\n",
    "df_netflix_4 = pd.read_csv(PARAM['path']['netflix']+'data_4.txt', names=names, low_memory=False)\n",
    "df_netflix = pd.concat([df_netflix,df_netflix_2,df_netflix_3,df_netflix_4], names=names)\n",
    "df_netflix['movieId'] = df_netflix['movieId'].fillna(method='ffill')\n",
    "df_netflix.dropna(inplace=True)\n",
    "df_netflix['rating'] = df_netflix['rating'].astype(np.int8)\n",
    "df_netflix['movieId'] = df_netflix['movieId'].astype(np.int16)\n",
    "df_netflix['userId'] = df_netflix['userId'].astype(np.int32)\n",
    "df_netflix['timestamp'] = pd.to_datetime(df_netflix['timestamp']).view(dtype=np.int64) // 10 ** 9\n",
    "df_movies = pd.read_csv(PARAM['path']['netflix']+'movie_titles.csv',\n",
    "                        encoding='latin-1',\n",
    "                        names=['movieId','release_year','title'],\n",
    "                        usecols=range(3))\n",
    "NETFLIX = {\n",
    "  'ratings': df_netflix[['userId','movieId','rating','timestamp']].sample(2**16),\n",
    "  'movies': df_movies,\n",
    "  'm_movies': df_netflix['movieId'].nunique(),\n",
    "  'n_users': df_netflix['userId'].nunique(),\n",
    "  'n_ratings': len(df_netflix)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 4)\n",
      "(17770, 3)\n"
     ]
    }
   ],
   "source": [
    "print(NETFLIX['ratings'].shape)\n",
    "print(NETFLIX['movies'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SVD Model\n",
      "Created\n",
      "Loading Data\n",
      "Loaded Data\n",
      "Spliting Data\n",
      "User Item Matrix Shape: userItemMatrix.shape\n",
      "User Reference length: self.n_users\n",
      "Item Reference length: self.n_items\n"
     ]
    }
   ],
   "source": [
    "PARAM['features'] = [3,30,150,300]\n",
    "PARAM['lr'] = [1e-2,1e-3,1e-4]\n",
    "PARAM['epochs'] = [11,101,201,301,501]\n",
    "PARAM['weight_decay'] = [0.02,0.2,2]\n",
    "PARAM['stopping'] = 0.001\n",
    " \n",
    "data = 'NETFLIX'\n",
    " \n",
    "if data=='ML_25M':\n",
    "    resultDir = 'model_movielens'\n",
    "else:\n",
    "    resultDir = 'model_netflix'\n",
    "\n",
    "print('Creating SVD Model')\n",
    "svd = SVDModel()\n",
    "print(\"Created\\nLoading Data\")\n",
    "if data=='ML_25M':\n",
    "    svd.data_loader(data=ML_25M['ratings'],\n",
    "                    n_items = ML_25M['m_movies'],\n",
    "                    n_users= ML_25M['n_users'])\n",
    "else:\n",
    "    svd.data_loader(data=NETFLIX['ratings'],\n",
    "                    n_items = NETFLIX['m_movies'],\n",
    "                    n_users= NETFLIX['n_users'])\n",
    "print(\"Loaded Data\\nSpliting Data\")\n",
    "svd.split(0.8,0.8)\n",
    "\n",
    "def train_model(features, lr, epochs, data, weight_decay):\n",
    "    if os.path.isfile(f'./{resultDir}/funk/result/{features}_{lr}_{epochs}_{weight_decay}_0.001.pkl'):\n",
    "        return\n",
    "    print(f\"==============================\")\n",
    "    print(f'features: {features}\\nlearning rate: {lr}\\nEpochs: {epochs}\\nweight decay: {weight_decay}\\nstopping: 0.001\\n')\n",
    " \n",
    "    svd.features = features\n",
    "    svd.lr = lr\n",
    "    svd.epochs = epochs\n",
    "    svd.weight_decay = weight_decay\n",
    " \n",
    "\n",
    "    print(\"Splitted Data\\nTraining...\")\n",
    "    start = time.perf_counter()\n",
    "    result = svd.training()\n",
    "    print('Time used =', time.perf_counter()-start)\n",
    "   \n",
    "    print('Saving Model')\n",
    "    # svd.data = []\n",
    "    Path(f\"./{resultDir}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"./{resultDir}/funk\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"./{resultDir}/funk/model\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"./{resultDir}/funk/result\").mkdir(parents=True, exist_ok=True)\n",
    "   \n",
    "   \n",
    "#     with open(f'./{resultDir}/funk/model/{features}_{lr}_{epochs}_{weight_decay}_0.001.pkl', 'wb') as out:\n",
    "#         pickle.dump(svd, out, pickle.HIGHEST_PROTOCOL)\n",
    "#         out.close()\n",
    "    with open(f'./{resultDir}/funk/result/{features}_{lr}_{epochs}_{weight_decay}_0.001.pkl', 'wb') as out:\n",
    "        pickle.dump(result, out, pickle.HIGHEST_PROTOCOL)\n",
    "        out.close()\n",
    "    print(f\"==============================\")\n",
    "    return svd, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epochs in PARAM['epochs']:\n",
    "    for features in PARAM['features']:\n",
    "        for lr in PARAM['lr']:\n",
    "            for weight_decay in PARAM['weight_decay']:\n",
    "                for data in ['NETFLIX']:\n",
    "                    train_model(features, lr, epochs, data, weight_decay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
