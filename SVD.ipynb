{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models import RecommendSystemModel\n",
    "\n",
    "from typing import List, Any, Tuple,Union\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to update class in Jupyter Notebook \n",
    "https://stackoverflow.com/questions/45161393/jupyter-split-classes-in-multiple-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def update_class(\n",
    "    main_class=None, exclude=(\"__module__\", \"__name__\", \"__dict__\", \"__weakref__\")\n",
    "):\n",
    "    \"\"\"Class decorator. Adds all methods and members from the wrapped class to main_class\n",
    "\n",
    "    Args:\n",
    "    - main_class: class to which to append members. Defaults to the class with the same name as the wrapped class\n",
    "    - exclude: black-list of members which should not be copied\n",
    "    \"\"\"\n",
    "\n",
    "    def decorates(main_class, exclude, appended_class):\n",
    "        if main_class is None:\n",
    "            main_class = globals()[appended_class.__name__]\n",
    "        for k, v in appended_class.__dict__.items():\n",
    "            if k not in exclude:\n",
    "                setattr(main_class, k, v)\n",
    "        return main_class\n",
    "\n",
    "    return functools.partial(decorates, main_class, exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def method1(self):\n",
    "        print(\"method1\")\n",
    "me = MyClass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method1\n",
      "method2\n"
     ]
    }
   ],
   "source": [
    "@update_class()\n",
    "class MyClass:\n",
    "    def method2(self):\n",
    "        print(\"method2\")\n",
    "me.method1()\n",
    "me.method2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDModel(RecommendSystemModel):\n",
    "    def __init__(self, mode:str=None, features: int = None, lr: float = None, epochs: int = None, weight_decay: float = None, stopping: float = None, momentum: float = None) -> None:\n",
    "        # Data frame\n",
    "        # self.data#:pd.DataFrame\n",
    "        # # Training data \n",
    "        # self.train#:pd.DataFrame\n",
    "        # # Validating Data\n",
    "        # self.valid#:pd.DataFrame\n",
    "        # self.test#:pd.DataFrame\n",
    "        # SVD mode \n",
    "        self.mode: str = mode or 'funk'\n",
    "        # Number of features\n",
    "        self.features: int = features or 10\n",
    "        # Learning rate\n",
    "        self.lr: float = lr or 0.0002\n",
    "        # Number of total epochs\n",
    "        self.epochs: int = epochs or 101\n",
    "        # the weight decay \n",
    "        self.weight_decay: float = weight_decay or 0.02\n",
    "        self.stopping: float = stopping or 0.001\n",
    "        self.momentum: float = momentum or 0.0\n",
    "        # Tensor SGD optimizer\n",
    "        # self.optimizer = tf.keras.optimizers.SGD(learning_rate=self.lr, momentum=self.momentum,)\n",
    "        \n",
    "        # # Rating matrix\n",
    "        # self.R: NDArray\n",
    "        # # User matrix\n",
    "        # self.P: NDArray\n",
    "        # # Item matrix\n",
    "        # self.Q: NDArray\n",
    "        \n",
    "        # Rating matrix\n",
    "        # self._R = self.R.copy()\n",
    "        # User latent matrix\n",
    "        self._P: NDArray# = np.random.rand(self.n_users, features) * 0.1\n",
    "        # Item latent matrix\n",
    "        self._Q: NDArray # = np.random.rand(self.n_items, features) * 0.1\n",
    "        \n",
    "        \n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def split(self, ratio_train_test: float, ratio_train_valid: float, tensor: bool = False) -> List[NDArray]:\n",
    "        userItemMatrix = self.convertToUserItemMatrix(self.data, self.n_users, self.n_movies)\n",
    "        \n",
    "        trainBeforeSplit = np.zeros((len(userItemMatrix), len(userItemMatrix[0]))).tolist()\n",
    "        self.train = np.zeros((len(userItemMatrix), len(userItemMatrix[0]))).tolist()\n",
    "        self.valid = np.zeros((len(userItemMatrix), len(userItemMatrix[0]))).tolist()\n",
    "        self.test = np.zeros((len(userItemMatrix), len(userItemMatrix[0]))).tolist()\n",
    "\n",
    "        for i in range(len(userItemMatrix)):\n",
    "            for j in range(len(userItemMatrix[i])):\n",
    "                if userItemMatrix[i][j] > 0:\n",
    "                    if np.random.binomial(1, ratio_train_test, 1):\n",
    "                        trainBeforeSplit[i][j] = userItemMatrix[i][j]\n",
    "                    else:\n",
    "                        self.test[i][j] = userItemMatrix[i][j]\n",
    "        \n",
    "        for i in range(len(trainBeforeSplit)):\n",
    "            for j in range(len(trainBeforeSplit[i])):\n",
    "                if trainBeforeSplit[i][j] > 0:\n",
    "                    if np.random.binomial(1, ratio_train_valid, 1):\n",
    "                        self.train[i][j] = trainBeforeSplit[i][j]\n",
    "                    else:\n",
    "                        self.valid[i][j] = trainBeforeSplit[i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def data_loader(self, path:str=None, nrows:int=None, skiprows=None, data:pd.DataFrame=None, n_users: int = None, n_items = None) -> None:\n",
    "        if not path and not data:\n",
    "            raise 'Error: one of path or data frame should be provided'\n",
    "        if not data:\n",
    "            self.data = pd.read_csv(path,low_memory=False,nrows=nrows,skiprows=skiprows)\n",
    "        elif not path:\n",
    "            self.data = data\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def train(self) -> Tuple[NDArray, NDArray, float, float]:\n",
    "        loss_train = []\n",
    "        loss_valid = []\n",
    "        errors = []\n",
    "\n",
    "        # self.n_users = len(self.train)\n",
    "        # self.n_items = len(self.valid)\n",
    "        self._P = np.random.rand(self.n_users, self.features) * 0.1\n",
    "        self._Q = np.random.rand(self.n_items, self.features) * 0.1\n",
    "\n",
    "        # Johnny\n",
    "        for e in range(self.epochs):\n",
    "            for id_user in range(self.n_users):\n",
    "                for id_item in range(self.n_items):\n",
    "                    if self.train[id_user][id_item] > 0:\n",
    "                        \n",
    "                        predict = self.prediction(self._P, self._Q, id_user, id_item)\n",
    "                        \n",
    "                        error = self.train[id_user][id_item] - predict\n",
    "                        errors.append(error)\n",
    "                        \n",
    "                        self.optimize(error, id_user, id_item, self.weight_decay)\n",
    "            trainLoss = self.loss(self.train, self._P, self._Q)\n",
    "            validLoss = self.loss(self.valid, self._P, self._Q)\n",
    "            loss_train.append(trainLoss)\n",
    "            loss_valid.append(validLoss)\n",
    "            if e % 10 == 0:\n",
    "                print('Epoch : ', \"{:3.0f}\".format(e+1), ' | Train :', \"{:3.3f}\".format(trainLoss), \n",
    "                    ' | Valid :', \"{:3.3f}\".format(validLoss))\n",
    "                \n",
    "            # TODO stopping criterion\n",
    "            if (trainLoss - loss_train[-2]) < self.stopping:\n",
    "                break\n",
    "        return loss_train, loss_valid, errors\n",
    "        # return super().learn_to_recommend(data, features, lr, epochs, weight_decay, stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def convertToUserItemMatrix(data, n_users, n_movies):\n",
    "        userItemMatrix = []\n",
    "        for id_user in range(1, n_users + 1):\n",
    "            id_movies = np.array([ratingRecord[1] for ratingRecord in data if ratingRecord[0] == id_user])\n",
    "            id_ratings = [ratingRecord[2] for ratingRecord in data if ratingRecord[0] == id_user]\n",
    "            ratings = np.zeros(n_movies)\n",
    "            ratings[id_movies - 1] = id_ratings\n",
    "            userItemMatrix.append(list(ratings))\n",
    "        return userItemMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def prediction(self, P: NDArray, Q: NDArray, u: int, i: int) -> float:\n",
    "        # Woody\n",
    "        return np.dot(P[u: ], Q[ :i])\n",
    "        # print(321)\n",
    "        # return super().prediction(P, Q, u, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def loss(self, groundTruthData, P: NDArray, Q: NDArray) -> float:\n",
    "        # Woody\n",
    "        squaredErrors = 0.0\n",
    "        numOfPrediction = 0\n",
    "        # nb_users, nb_items = len(data), len(data[0])\n",
    "\n",
    "        for u in range(self.n_users):\n",
    "            for i in range(self.n_items):\n",
    "                if groundTruthData[u][i] > 0:\n",
    "                    squaredErrors += pow(groundTruthData[u][i] - self.prediction(P, Q, u, i), 2)\n",
    "                    numOfPrediction += 1\n",
    "                    \n",
    "        return squaredErrors / numOfPrediction\n",
    "        print(654)\n",
    "        # return super().loss(data, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class SVDModel(RecommendSystemModel):\n",
    "    def optimize(self, error:float, id_user:int, id_item:int,weight_decay):\n",
    "        # Johnny\n",
    "        # P[id_user] = self.optimizer.minimize(P[id_user], [error])\n",
    "        # Q[id_item] = self.optimizer.minimize()\n",
    "        # return super().svd()\n",
    "        \n",
    "        self._P[:, id_user] += self.lr * (error * self._Q[:, id_item] - weight_decay * self._P[:, id_user])\n",
    "        self._Q[:, id_item] += self.lr * (error * self._P[:, id_user] - weight_decay * self._Q[:, id_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVDModel()\n",
    "# svd.svd()\n",
    "# svd.learn_to_recommend(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths\n",
    "data_path = './data/MovieLens25M/'\n",
    "df_rating = pd.read_csv(data_path+'ratings.csv')\n",
    "df_movies = pd.read_csv(data_path+'movies.csv')\n",
    "m_movies = df_rating['movieId'].nunique()\n",
    "n_users = df_rating['userId'].nunique()\n",
    "n_ratings = len(df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.data_loader(path=\"./data/MovieLens25M/ratings.csv\", n_items = m_movies, n_users=n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59047\n",
      "{'mode': 'funk', 'features': 10, 'lr': 0.0002, 'epochs': 101, 'weight_decay': 0.02, 'stopping': 0.001, 'momentum': 0.0, 'data':           userId  movieId  rating   timestamp\n",
      "0              1      296     5.0  1147880044\n",
      "1              1      306     3.5  1147868817\n",
      "2              1      307     5.0  1147868828\n",
      "3              1      665     5.0  1147878820\n",
      "4              1      899     3.5  1147868510\n",
      "...          ...      ...     ...         ...\n",
      "25000090  162541    50872     4.5  1240953372\n",
      "25000091  162541    55768     2.5  1240951998\n",
      "25000092  162541    56176     2.0  1240950697\n",
      "25000093  162541    58559     4.0  1240953434\n",
      "25000094  162541    63876     5.0  1240952515\n",
      "\n",
      "[25000095 rows x 4 columns], 'valid': None, 'train': None, 'n_users': 162541, 'n_items': 59047}\n"
     ]
    }
   ],
   "source": [
    "print(svd.n_items)\n",
    "print(svd.__dict__)\n",
    "# svd.n_items = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.split(0.6,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVDModel' object has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/woody/HKUProject/HOAI/movie-recommender/SVD.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/woody/HKUProject/HOAI/movie-recommender/SVD.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(svd\u001b[39m.\u001b[39;49mtest)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVDModel' object has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "print(svd.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "700a48a79e01336b565934c39e82c651368cb6d560b25f670fa29b80c90d337c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
