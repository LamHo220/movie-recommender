{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVDModel import SVDModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(3362)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PARAM = dict()\n",
    "PARAM['path'] = {\n",
    "  'ml':'./data/MovieLens25M/',\n",
    "  'netflix':'./data/NetflixPrize/'\n",
    "}\n",
    "\n",
    "PARAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_25M = {\n",
    "#   'ratings': pd.read_csv(PARAM['path']['ml']+'ratings.csv', dtype={\n",
    "#     'userId': np.int32,\n",
    "#     'movieId': np.int32,\n",
    "# #     'rating': np.float64,\n",
    "#     'timestamp':np.float64}).sample(2**16),\n",
    "#   'movies': pd.read_csv(PARAM['path']['ml']+'movies.csv', dtype= {\n",
    "#     'movieId':np.int32,\n",
    "#     'title': str,\n",
    "#     'genres': str\n",
    "#   })\n",
    "# }\n",
    "# ML_25M['m_movies'] = ML_25M['movies']['movieId'].nunique()\n",
    "# ML_25M['n_users'] = ML_25M['ratings']['userId'].nunique()\n",
    "# ML_25M['n_ratings'] = len(ML_25M['ratings'])\n",
    "\n",
    "\n",
    "# ML_25M['movies'].insert(1, 'newMovieId', value=range(1,len(ML_25M['movies'])+1))\n",
    "# newMovieIdDict = {}\n",
    "# for index, movie in ML_25M['movies'].iterrows():\n",
    "#     newMovieIdDict[movie['movieId']] = movie['newMovieId']\n",
    "# ML_25M['ratings'].replace({\"movieId\": newMovieIdDict}, inplace=True)\n",
    "# ML_25M['ratings']['rating'] = ML_25M['ratings']['rating'].astype(np.float16)\n",
    "\n",
    "# ML_25M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ML_25M['ratings'].size)\n",
    "# print(ML_25M['movies'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['userId','rating','timestamp','movieId']\n",
    "df_netflix = pd.read_csv(PARAM['path']['netflix']+'data_1.txt', names=names, low_memory=False)\n",
    "df_netflix_2 = pd.read_csv(PARAM['path']['netflix']+'data_2.txt', names=names, low_memory=False)\n",
    "df_netflix_3 = pd.read_csv(PARAM['path']['netflix']+'data_3.txt', names=names, low_memory=False)\n",
    "df_netflix_4 = pd.read_csv(PARAM['path']['netflix']+'data_4.txt', names=names, low_memory=False)\n",
    "df_netflix = pd.concat([df_netflix,df_netflix_2,df_netflix_3,df_netflix_4], names=names)\n",
    "df_netflix['movieId'] = df_netflix['movieId'].fillna(method='ffill')\n",
    "df_netflix.dropna(inplace=True)\n",
    "df_netflix['rating'] = df_netflix['rating'].astype(np.int8)\n",
    "df_netflix['movieId'] = df_netflix['movieId'].astype(np.int16)\n",
    "df_netflix['userId'] = df_netflix['userId'].astype(np.int32)\n",
    "df_netflix['timestamp'] = pd.to_datetime(df_netflix['timestamp']).view(dtype=np.int64) // 10 ** 9\n",
    "df_movies = pd.read_csv(PARAM['path']['netflix']+'movie_titles.csv',\n",
    "                        encoding='latin-1',\n",
    "                        names=['movieId','release_year','title'],\n",
    "                        usecols=range(3))\n",
    "NETFLIX = {\n",
    "  'ratings': df_netflix[['userId','movieId','rating','timestamp']].sample(2**12),\n",
    "  'movies': df_movies,\n",
    "  'm_movies': df_netflix['movieId'].nunique(),\n",
    "  'n_users': df_netflix['userId'].nunique(),\n",
    "  'n_ratings': len(df_netflix)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "262144\n",
    "53310\n",
    "'''\n",
    "print(NETFLIX['ratings'].shape)\n",
    "print(NETFLIX['movies'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM['features'] = [3,5,10,100,200,300]\n",
    "PARAM['lr'] = [1e-2,1e-3,1e-4,1e-5]\n",
    "PARAM['epochs'] = [11,101,201,301,501,1001]\n",
    "PARAM['weight_decay'] = 0.02\n",
    "PARAM['stopping'] = 0.001\n",
    "\n",
    "def train_model(features, lr, epochs, data):\n",
    "    print(f\"==============================\")\n",
    "    print(f'features: {features}\\nlearning rate: {lr}\\nEpochs: {epochs}\\nweight decay: 0.02\\nstopping: 0.001')\n",
    "#     if os.path.isfile(f'./model_netflix/svd_{features}_{lr}_{epochs}_0.02_0.001.pkl'):\n",
    "#         with open(f'./model_netflix/svd_{features}_{lr}_{epochs}_0.02_0.001.pkl', 'rb') as inp:\n",
    "#             loaded_svd = pickle.load(inp)\n",
    "#             print('Found existing model loaded it')\n",
    "#         with open(f'./model_netflix/result_{features}_{lr}_{epochs}_0.02_0.001.pkl', 'rb') as inp:\n",
    "#             loaded_result = pickle.load(inp)\n",
    "#             print('Found existing result loaded it')\n",
    "#         return loaded_svd, loaded_result\n",
    "    print('Creating SVD Model')\n",
    "    svd = SVDModel(\n",
    "        features=features, \n",
    "        lr=lr, \n",
    "        epochs=epochs, \n",
    "        weight_decay=PARAM['weight_decay'], \n",
    "        stopping=PARAM['stopping']\n",
    "    )\n",
    "    print(\"Created\\nLoading Data\")\n",
    "    if data=='ML_25M':\n",
    "        svd.data_loader(data=ML_25M['ratings'], \n",
    "                        n_items = ML_25M['m_movies'], \n",
    "                        n_users= ML_25M['n_users'])\n",
    "    else:\n",
    "        svd.data_loader(data=NETFLIX['ratings'], \n",
    "                        n_items = NETFLIX['m_movies'], \n",
    "                        n_users= NETFLIX['n_users'])\n",
    "    print(\"Loaded Data\\nSpliting Data\")\n",
    "    svd.split(0.6,0.8)\n",
    "    print(\"Splitted Data\\nTraining...\")\n",
    "    start = time.perf_counter()\n",
    "    result = svd.training()\n",
    "    print('Time used =', time.perf_counter()-start)\n",
    "    \n",
    "    print('Saving Model')\n",
    "    svd.data = []\n",
    "    Path(\"./model_netflix\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(f'./model_netflix/svd_{features}_{lr}_{epochs}_0.02_0.001.pkl', 'wb') as out:\n",
    "        pickle.dump(svd, out, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'./model_netflix/result_{features}_{lr}_{epochs}_0.02_0.001.pkl', 'wb') as out:\n",
    "        pickle.dump(result, out, pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"==============================\")\n",
    "    return svd, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svds = []\n",
    "results = []\n",
    "for epochs in PARAM['epochs']:\n",
    "    for features in PARAM['features']:\n",
    "        for lr in PARAM['lr']:\n",
    "            for data in ['NETFLIX']:\n",
    "                svd,result = train_model(features, lr, epochs, data)\n",
    "                svds.append(svd)\n",
    "                results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
